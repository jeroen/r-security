 %%This is a very basic article template.
%%There is just one section and two subsections.
\documentclass[article]{jss}

\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage{appendix}

\newcommand{\R}{\textsf{R}\xspace}
\newcommand{\Java}{\textsf{Java}\xspace}
\newcommand{\C}{\textsf{C}\xspace}
\newcommand{\Cpp}{\textsf{C++}\xspace}
\newcommand{\Fortran}{\textsf{Fortran}\xspace}
\newcommand{\Python}{\textsf{Python}\xspace}
\newcommand{\Ruby}{\textsf{Ruby}\xspace}

\newcommand{\AppArmor}{\texttt{AppArmor}\xspace}
\newcommand{\RAppArmor}{\pkg{RAppArmor}\xspace}
\newcommand{\Linux}{\texttt{Linux}\xspace}
\newcommand{\ULIMIT}{\texttt{ULIMIT}\xspace}
\newcommand{\RLIMIT}{\texttt{ULIMIT}\xspace}

%% almost as usual
\author{Jeroen Ooms\\UCLA Dept. of Statistics 
     %   \And Second Author\\Plus Affiliation
}
\title{The \RAppArmor Package: Enforcing Security Policies in \R Using Dynamic
Sandboxing on Linux}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Jeroen Ooms} %% comma-separated
\Plaintitle{The RAppArmor Package: Enforcing Security Policies in R using Dynamic
Sandboxing on Linux} %% without formatting
\Shorttitle{The RAppArmor Package} %% a short title (if
% necessary)


%% an abstract and keywords
\Abstract{
  With the increasing availability of public cloud computing facilities and
  scientific super computers, there is a great potential for making
  \R available through public or shared resources. This allows
  researchers to efficiently run code requiring a lot of cycles and memory,
  or embed \R functionality into e.g.\ systems or web services.
  However some important security concerns need to be addressed before this
  can be put in production. The prime use case in the design of \R has
  always been single statistician running \R on the local machine
  through the interactive console. As a result there are practically no restrictions on
  what the user is allowed to do with the operating system, which could
  potentially result in malicious behavior or excessive use of hardware resources
  in a shared environment. Properly securing an \R process turns
  out to be a complex problem. We describe several approaches 
  and illustrate potential issues using some of our personal experiences in
  hosting public web services. Finally we introduce the \RAppArmor package which
  provides a Linux based reference implementation for dynamic sandboxing in
  \R on the level of the operating system. }


\Keywords{R, Security, Linux, Sandbox, AppArmor}
\Plainkeywords{R, security, linux, sandbox, apparmor}

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Jeroen Ooms\\
  UCLA Department of Statistics\\
  University of California\\
  E-mail: \email{jeroen.ooms@stat.ucla.edu}\\
  URL: \url{http://www.stat.ucla.edu/~jeroen}
}

\begin{document}

\section[Security in R: Introduction and motivation]{Security in \R:
Introduction and motivation}

The \R project for statistical computing and graphics
\citep{R-project} is currently one of the primary tool-kits for scientific
computing. The software is widely used for research and data analysis in both
academia and industry, and is the de-facto standard among statisticians for the
development of new computational methods. With support for all major
operating systems, a powerful and stable codebase, more than 3000 add-on
packages and a huge active community, it is fair to say that the project has
matured to a production-ready computation tool. However, one thing that is
somewhat surprising is that the way in which \R is used, has hardly
changed since its initial design. Even though internet access, public
cloud computing \citep{armbrust2010view}, live and open sources of data and
scientific super computers have transformed the landscape of data analysis, \R
is still almost exclusively used as an end-user tool, running on the local
machine of the researcher, operated through the interactive console. This seems
somewhat of a missed opportunity. The demand for data analysis tools has never
been higher, and many open source systems and software stacks could benefit
greatly from the high quality analytical capabilities that \R has to
offer.

One reason developers are reluctant to build on \R are concerns regarding
security and management of shared hardware resources. Reliable software systems
require components which behave predictably and cannot be abused. Because
\R was primarily designed with the local user in mind, security issues and
unpredictable behavior have not been considered a major concern in the design
of \R itself. Hence, these problems will need to be addressed somehow before
software developers will feel comfortable making \R part of their
infrastructure, or convince administrators to use their facilities to expose \R
based services to the public. It is our personal experience that the complexity of these issues is easily
underestimated when designing stacks or systems that build on \R.
There are a number of issues that are very domain specific to scientific
computing, which makes building on \R quite different from embedding
other software or languages. We suspect that this might explain the limited
adoption of \R as a computational back-end engine so far.

\subsection{Security when using contributed code}


Building systems on \R has been the main motivation for this research.
However, security is becoming a concern for \R in other contexts as
well. As the community is growing rapidly, it becomes more unsafe
to rely on the social aspect of contributed code. For example, on a daily
basis, dozens of packages and package updates submitted to the
\emph{Comprehensive R Archive Network} (CRAN) \citep{ripleycran}.
These packages contain code written in \R, \C, \Fortran, \Cpp, \Java, etc. It
is practically impossible for the CRAN maintainers to do a thorough audit of the
full code that is submitted, every time. Some packages even contain pre-compiled \Java code for which the source is not included at all. Furthermore, \R packages
are not signed with a private key as is the case for e.g.\ packages in most
\Linux distributions, which makes it hard to verify the identity of the author. As
CRAN packages are automatically build and installed on hundreds, maybe thousands
of machines around the world, they form an interesting target for abuse.
Hence there could be a real risk of packages containing malicious code making
their way unnoticed into CRAN. Risks are even greater for packages 
distributed through channels without any form of code review, for example via
email or through the increasingly popular Github repositories
\citep{torvalds2010git,dabbish2012social}.

In summary, it is not overly paranoid of the \R user to be a bit
cautious when installing and running contributed code downloaded from the
internet. However, things don't have to be as serious as described above.
Thinking about security is a good practice, even if there are no immediate reasons
for concern. Some users simply might want to protect against themselves, making
sure they don't erase any files by accident and that \R does not
interfere with other activities on the machine. Making an effort to ensure
\R is running safely with no unnecessary privileges can be reassuring 
to both user and system administrator, and might one day prevent a lot of trouble.

\subsection[Sandboxing the R environment]{Sandboxing the \R environment}


This paper explores some of the potential problems, along with approaches and
methods of securing \R. Some of the different aspects and concerns of
security in the context of \R are illustrated using personal
experiences, or examples of bad or malicious code. We will explain how untrusted
code can be run inside a \emph{sandboxed} process. Sandboxing in
this context is a somewhat informal term for creating an environment in which
untrusted software runs without capabilities of doing anything harmful to the
system. As it turns out, \R itself is not very suitable for managing
access control policies, and the only way to enforce security properly is by
leveraging features from the operating system. To exemplify this approach, an
implementation based on \AppArmor is provided which can be
used on \Linux distributions as the basis for a sandboxing toolkit. This package
is used throughout the paper to show some of the issues could be addressed.

However, we want to emphasize that we don't claim to have solved the problem.
This paper mostly serves an introduction to security for the \R
community, and hopefully creates some awareness that this is a real issue moving
forward. The \RAppArmor package is one approach and a good starting point
for experimenting with dynamic sandboxing in \R. However it mostly
serves as a proof of concept of the general idea confining and controlling \R
in order to extend the applicability. The paper describes some examples of use
cases, issues, policies and personal experiences which give the reader a sense
of what is involved with this topic. Without any doubt, there are other concerns
beyond the ones mentioned in this paper, many of which might be specific to
certain applications or systems. We hope to invoke a discussion in the community
about potential security issues related to using \R in
different scenarios, and encourage those comfortable with other platforms or who
use \R in different contexts to join the discussion and share their
concerns, experiences and solutions.

\section[Use cases and concerns of sandboxing R]{Use cases and concerns of
sandboxing \R}

Let us start by taking a step back and put this research in perspective by
describing some concrete use cases where security in \R could be a
concern. Below are three simple examples of situations in which it is useful to
be able to run \R code in a sandbox. The use cases are ordered by
complexity and require increasingly advanced sandboxing methods.


\subsubsection{Running untrusted code}

Suppose we found an \R package in our email or on the internet that
looks interesting, but we are not quite sure who the author is, and if the
package does not contain any malicious code. The package is too large for us to
inspect all of the code manually, and furthermore it contains a library in a
foreign language (e.g.\ \Cpp, \Fortran) for which we lack
the knowledge and insight to really understand the code. Moreover, the
programming style (or lack thereof) of the author can make it difficult to
assess what exactly is going on \citep{ioccc}. Nevertheless we would like to
give the package a try, but without exposing ourselves to the risk of potentially
jeopardizing the machine.

One solution would be to run the code on a separate or virtual machine. However
this is somewhat cumbersome and we will not have our regular workflow available:
in order to put the package to the test on our own data, we first need to
copy our data, scripts, files and package library, etc. In practice creating new
machines is a bit unpractical and not something that we might want to do on a
daily basis. It would be easier if we could just sandbox our regular \R
environment for the duration of installing and using the new package. If the
sandbox is flexible and unobtrusive enough to not interrupt our daily workflow,
we could even make a habit out of using it every time we use contributed code
(which for most users is every day).

\subsubsection{Shared resources}

Another use case could be a scenario where multiple users are sharing a single
machine. For example, a system administrator at a university is managing a big
computing resource and would like to make it available to faculty and students
for using \R. This way they could run \R code that requires
more computing power than their local machine can handle. For example a
researcher might want to do a simulation study, and fit a complex model a
million times on generated datasets of varying properties. On her own machine
this would take months to complete, but the super computer can finish the job
overnight. The administrator would like to make the supercomputer accessible to
this and other researchers for running their \R code. However he is
concerned about users interfering with each others work, or breaking anything
on the machine. Furthermore he wants to make sure that system resources are
allocated in a fair way so that no single user can consume all memory or cpu on
the system.

\subsubsection{Embedded systems and services}

There have been a number of efforts to facilitate integration of \R
functionality into various 3rd party systems. Some examples of interfaces from
popular general purpose languages are \texttt{RInside} \citep{RInside}, which
embeds \R into \Cpp environments, and JRI/REngine \texttt{JRI} which
embeds \R in \Java software \citep{JRI,urbanek2007rjava}. Similarly,
\texttt{rpy} \citep{moreira2006rpy,gautier2008rpy2} provides a \Python interface to \R, and
\texttt{RinRuby} is a \Ruby library that integrates the \R interpreter in Ruby
\citep{dahl2008rinruby}. Littler provides hash-bang (i.e.\ script starting with \texttt{\#!/some/path}) capability for
\R \citep{littler}. The Apache2 module RApache  (\texttt{mod\_R})
\citep{rapache} makes it possible to run \R scripts from within the
Apache2 web server. \cite{heiberger2009r} provide a series of tools to call
\R from DCOM clients on Windows environments, mostly to support
calling \R from Microsoft Excel. Finally, \texttt{RServe} is TCP/IP
server which provides low level access to an \R session over a socket
\citep{Rserve}.

The third use case originates from these developments: it can be summarized as
confining and managing \R processes inside of embedded systems and
services. This use case is largely derived from our personal experience: we are
using \R inside a number of systems and web services that provide
on-demand calculations and plotting over the internet. These services have to
respond quickly and with minimal overhead to incoming requests, and should
scale to serve many jobs per second. Furthermore the systems have to be stable,
requiring that jobs should always return within a given timeframe. Depending on
user and the type of job, different security restrictions might be appropriate.
Also we need a way to dynamically enforce limits on the use of memory,
processors and disk space on a per process basis. These requirements demands
a more flexible and finer degree of control over the process privileges and
restrictions than the first two use cases. It encouraged us to explore more
advanced methods than the conventional tools and has been the most central
motivation of this research.

\subsection{System privileges and hardware resources}

The use cases described above provide motivations and requirements for an
\R sandbox. Two inter-related problems can be distinguished. The first
one is preventing system abuse, i.e.\ use of the machine for malicious or
undesired activities, or completely compromising the machine. The second
problem is managing sharing of hardware resources, i.e.\ preventing excessive
use of resources by limiting the amount of memory, cpu, etc that a single user
or process is allowed to consume.

\subsubsection{System abuse}

The \R console gives the user direct access to the operating system
and does not implement any privileges restrictions or access control policies to
prevent malicious use. In fact, some of the basic functionality in \R actually
assumes quite profound access to the system, e.g.\ read access to system files,
or the privilege of running system shell commands. However, running 3rd
party \R code without any restrictions can get us in serious
trouble. For example, the code could call the \texttt{system()} function which
provides an interface to the system shell. From here any system commands can be
executed, which can potentially be harmful. But also innocent looking functions
like \texttt{read.table} can be used to extract sensitive information from the
system, e.g.\ \texttt{read.table("/etc/passwd")} will gives us a list of users
on the system or \texttt{readLines("/var/log/syslog")} shows system log
information.

Even an \R process running as a non-privileged user can do a lot of
harm. Some potential issues are code that contains or downloads a virus or
security exploit, or searches the system for personal or sensitive information.
Appendix \ref{creditcard} shows a hypothetical example of a simple function that
scans the home directory for documents containing credit card numbers. Another
increasing global problem are viruses which make the machine part of a so called
``botnet''. Botnets are large networks of compromised machines (``bots'') which
are remotely controlled to used for illegal activities
\citep{abu2006multifaceted}. Once infected, the botnet virus connects to a
centralized server and waits for instructions from the owner of the botnet.
Botnets are mostly used to send spam or to participate in DDOS attacks:
centrally coordinated operations in which a large number of machines on the
internet is used to flood a target server or provider with network traffic with
the goal of taking it down by overloading it \citep{mirkovic2004taxonomy}. Botnet
software is often invisible to the user of an infected machine and can run with
very little privileges: just network access is sufficient to do most of the work.

When using \R on the local machine and only running our own code, or
from trusted sources, these scenarios might sound a bit far fetched. However,
when running code downloaded from the internet or exposing systems to the
public, this is becoming a real concern. Internet security is a global problem,
and there are a large number of individuals, organizations and even governments
actively employing increasingly advanced and creative ways of gaining access to
protected infrastructures. Especially servers running on beefy hardware or
fast connections are attractive targets for individuals that could use these
resources for other purposes. But also servers and users inside large companies,
universities or government institutions are frequently targeted with the goal
of gathering confidential knowledge. This last aspect seems especially
relevant, as \R is used frequently in these types of organizations.

\subsubsection{Resource restrictions}

The other category of problems is not so much related to deliberate abuse, and
might even arise completely unintentionally. It involves problems requiring
proper management, allocation, sharing and restricting of hardware. 

It is fair to say that \R can be quite greedy with system resources.
One can easily run a command which will consume all of the available memory
and/or CPU, and does not finish executing unless manually terminated. When
running \R on the local machine through the interactive console, the
user will quickly recognize a function call that is not returning timely or is
making the machine unresponsive. When this happens, we can easily interrupt the
process prematurely by sending a \texttt{SIGINT}, i.e.\ pressing \texttt{CTRL+C}
in \Linux or \texttt{ESC} in Windows. If this doesn't work we can open the task
manager and tell the operating system to kill the process, and if worst comes
to worst we can decide to reboot our machine.

However, when \R is embedded in a bigger system, things are
more complicated, and we have to think about these scenarios in advance. When
an out-of-control \R job is not properly detected and terminated, the process
might very well run forever and take down our service, or even the entire server. This has
actually been a major problem that we personally experienced in an early
implementation of a public web service for mixed modelling \citep{yeroonlme4}
which uses the \texttt{lme4} package \citep{lme4}. What happened was that users
could accidentally specify a variable with many levels as the \emph{grouping
factor} which would cause the design matrix to blow up, even on a relatively
small dataset, and decompositions would take forever to complete. To make
things worse, \texttt{lme4} uses a lot of \texttt{C} code which does not
respond to time limits set by R's \texttt{setTimeLimit} function. Appendix
\ref{cputime} contains a code snippet that simulates this scenario. When this
would happen, the only way to get things up and running again was to manually
login to the server and reset the application.

This example is not an exception. The behavior of \R can sometimes be
unpredictable, which is an aspect that is easily overlooked by
(non-statistician) developers. When a system calls out to e.g.\ an \texttt{SQL}
or \texttt{PHP} script, the script usually runs without any problems and the
time needed to process is proportional to the size of the data, i.e.\ the number
of returned records returned by \texttt{SQL}. However, in an \R
script, many things can go wrong, even though the script itself is perfectly
fine. Algorithms might not converge, data might be rank-deficient, or missing
values throw a spanner in the works. Even when we only use tested code or
predefined services, this does not always entirely guarantee smooth and timely
completion of \R jobs, especially if the data is dynamic. When using
\R in systems or shared facilities, it is important that we take this
aspect into account and have a way of dealing with this that does not require
manual intervention.

\section[Different approaches of confining R]{Different approaches of confining
\R}

The current section introduces some approaches of securing and sandboxing
\R, with their advantages and limitations. They are reviewed in the
context of our use cases, and evaluated on how they address the problems of
system abuse and restricting resources. The approaches are increasingly
\emph{low-level}: they represent security on the level of the application, R
software itself and operating system respectively. As will become clear, we are
leaning towards the opinion that \R itself is not very well suited to address security issues, and the only way to do proper sandboxing is on the level of the
operating system. This will lead us to the introduction of the \RAppArmor
package, which is described in the section \ref{rapparmor}.


\subsection{Application level security: Predefined services}

The most common approach to preventing system abuse is simply to only allow a
limited set of predefined services, that have been deployed by a trusted
developer and cannot be abused. This is generally the case in websites
containing dynamic content though e.g.\ \proglang{CGI} or \proglang{PHP} scripts.
Running arbitrary code is explicitly prevented and any possibility to do so
anyway is considered a security hole. For example, we might want to expose the
following function as a web service:

\begin{CodeChunk}
\begin{CodeInput}
liveplot <- function (ticker) {
  url <- paste("http://ichart.finance.yahoo.com/table.csv?s=",
    ticker, "&a=07&b=19&c=2004&d=07&e=13&f=2020&g=d&ignore=.csv",
    sep = "")
  mydata <- read.csv(url)
  mydata$Date <- as.Date(mydata$Date)
  myplot <- ggplot2::qplot(Date, Close, data = mydata, geom = c("line",
    "smooth"), main = ticker)
  print(myplot)
}
\end{CodeInput}
\end{CodeChunk}

The function above downloads live data from the public API at Yahoo Finance and
creates an on-demand plot of the historical prices using \texttt{ggplot2}
\citep{ggplot2}. The function has only one parameter, \texttt{ticker}, which is
a character string identifying a stock symbol. This function can be exposed as a
predefined web service, where the client only supplies the \texttt{ticker}
argument. Hence the system does not need to run any potentially harmful
user-supplied \R code. The client sets the symbol to e.g.
\texttt{"GOOG"} and the resulting plot can be returned in the form of a
PNG image or PDF document. This function is actually the basis of the
``stockplot'' web application \citep{stockplot}; an interactive graphical web
application for financial analysis which still runs today.

Limiting users or clients to execute only predefined services is often the
easiest solution, but rather limited in application and actually not 100\%
secure. A predefined service can be nice to do some canned calculations or
generate a plot as done in the example, but for most \R applications
it quickly turns out to be overly restrictive. For example in case of an
application that allows the user to fit a statistical model, the user might
need to be able to include transformations of variables like \texttt{I(cos(x\^\ 2))} or \texttt{cs(x, 3)}. Not allowing a
user to call any custom functions makes this hard to implement.
Furthermore, when using only predefined services, all the work and
responsibility is put in the hands of the developer and administrator. Only they
can expose new services and they have to make sure that all services that are
exposed cannot be abused in some way or another. Therefore this approach is
expensive, and not very social in terms of users contributing code. In practice,
anyone that wants to publish an \R service will have to purchase and
manage a personal server or know someone that is willing to do so.

Also it might still be necessary to set hardware limitations, even when exposing
relatively simple, restricted services. We already mentioned the example of the
\texttt{lme4} web application, where a single user could accidentally take down
the entire system by specifying an overly complex model. Hence, restricting to
predefined services does not quite guarantee smooth and timely completion of
\R jobs.

\subsubsection{Code injection}

Finally, there is still the risk of \emph{code injection}. Because \R
is a very dynamic language, evaluations sometimes happen at unexpected places.
One example is during the parsing of \texttt{formulas}. For example, we might
want to publish a service that calls the \texttt{lm()} function in \R
on a fixed dataset. Hence the only thing the user can supply is a \emph{formula}
in the form of a character vector. Assume in the code snippet below that
the \texttt{userformula} is a string that has been supplied by a user through
some graphical interface.

\begin{CodeChunk}
\begin{CodeInput}
glm(userformula, data=cars)
\end{CodeInput}
\end{CodeChunk}

For example the user might supply a string \texttt{"speed
{\raise.17ex\hbox{$\scriptstyle\sim$}} dist"} and the service will return the
coefficients. On first sight, this might seem like a safe service. However,
formulas actually allow for the inclusion of calls to other functions. So even though the \texttt{userformula} is a character vector, we can actually use it to inject a
function call:

\begin{CodeChunk}
\begin{CodeInput}
userformula <- "speed ~ dist + system('whoami')"
lm(userformula, data=cars)
\end{CodeInput}
\end{CodeChunk}

In the example above, \texttt{lm} will automatically convert
\texttt{userformula} from type character to a \texttt{formula}, and
subsequently execute the \texttt{system('whoami')} command. So even when a
client can supply only very simple primitive data, there can still arise
unexpected opportunities of injecting arbitrary code. Therefore it is important
when using this approach, to sanitize the input before executing the service.
One way to do so is to set up the service in such a way that only alphanumeric
values are needed for the parameters, and use a regular expression to remove
any other characters, before actually executing the script or service:

\begin{CodeChunk}
\begin{CodeInput}
myarg <- gsub("[^a-zA-Z0-9]", "", myarg)
\end{CodeInput}
\end{CodeChunk}


\subsection{Sanitizing and blacklisting}

A less restrictive approach is to allow users to push custom \R code, but
inspect the code before evaluating it to make sure it does not contain malicious calls.
This approach has been adopted with some web sites that allow users to run
\R code, like \cite{banfield1999rweb} and \cite{cloudstat}. However,
given the dynamic nature of \R, this is actually very hard to do and
is often easy to circumvent. For example, one might want to prevent users from
calling the \texttt{system} function. One way is to define some smart regular
expressions that look for the word ``system'' in a block of code. This way
it would be possible to detect a potentially malicious call like this:

\begin{CodeChunk}
\begin{CodeInput}
system("whoami")
\end{CodeInput}
\end{CodeChunk}

However, it will be much harder to detect the equivalent call in the following
block:

\begin{CodeChunk}
\begin{CodeInput}
foo <- get(paste("sy", "em", sep="st"))
bar <- paste("who", "i", sep="am")
foo(bar)
\end{CodeInput}
\end{CodeChunk}

And indeed, it turns out that the services that use this approach are fairly
easy to trick. Because \R is a dynamic scripting language, the exact
function calls might not reveal themselves until runtime, when it is often too
late. We are actually quite convinced that it is nearly impossible to really
sanitize an \R script just by inspecting the source code.

An alternative method to do sanitizing is to define an extensive whitelist of
functions that a user is allowed to call, and mask all other functions. The
\pkg{sandboxR} \citep{sandboxR} package uses this method to block access
to all \R functions that provide access to the file system. It evaluates
the user-supplied code in an environment in which all blacklisted
functions are masked from the calling namespace. This is fairly effective and
can be useful for some applications. However, the method relies on exactly
knowing and specifying which functions are \emph{safe} and which are not. The
package author has done this for the thousands of \R functions in the
base package and we assume he has done a good job. However, it makes it hard to
maintain and cumbersome to generalize the approach to other \R packages (by
default the method does not allow loading other packages). Furthermore the
entire method falls if there is one function that has been
overlooked, which does make the method somewhat vulnerable.

Moreover, even when sanitizing of the code is successful, this method does not
limit the use of hardware resources in any way. Hence, additional methods are
still required to prevent excessive use of resources in a public environment.

\subsection{Sandboxing on the level of the operating system}

One can argue that managing resources and privileges is something that
is outside the domain of the \R software, and is better left to the
operating system. The \R software has been designed for statistical
computing and related functionality; the operating system deals with hardware
and security related matters. Hence, in order to really sandbox \R
properly without imposing unnecessary limitations on its functionality, we need
to sandbox the \emph{process} on the level of the operating system. When
restrictions are enforced by the operating system instead of \R
itself, we do not have to worry about all of the pitfalls and implementation
details of \R. The user can interact freely with \R, but
won't be able to do anything for which the system does not grant permission. 

Some operating systems offer more advanced capabilities for setting process
restrictions than others. The most advanced functionality is found in
\texttt{UNIX} like systems, of which the most popular ones are either
\texttt{BSD} based (\texttt{FreeBSD, OSX,} etc) or \Linux Based
(\texttt{Debian, Ubuntu, Fedora, Suse,} etc). Most \texttt{UNIX} like
systems implement some sort of \ULIMIT functionality to facilitate
restricting availability of hardware resources on a per-process basis.
Furthermore, on both \texttt{BSD} and \Linux there are a number of
\emph{Mandatory Access Control} (MAC) systems available. On \Linux,
these are implemented as Kernel modules. The most popular ones are \AppArmor
\citep{apparmor}, \texttt{SELinux} \citep{selinux} and \texttt{Tomoyo Linux}
\citep{tomoyo}. MAC provides a much finer degree of control than standard
user-based privileges, by applying advanced security policies on a per-process
basis.

Using a combination of MAC and \ULIMIT tools we can do a pretty
decent job in sandboxing a single \R process to a point where it can do little
harm to the system. Hence we can run arbitrary \R code without losing
any sleep over potentially jeopardizing the machine. Unfortunately, this
approach comes at the cost of portability of the software. As different
operating systems implement very different methods for managing processes and
privileges, the solutions will be to a large extend OS-specific. In our
implementation we have tried to hide these system calls by exposing \R functions
to interact with the kernel. Going forward, eventually these functions could
behave somewhat OS specific, abstracting away technicalities and providing
similar functionality on different systems. But for now we limit ourselves to
systems based on the \Linux kernel.

\section[The RAppArmor package]{The \RAppArmor package}
\label{rapparmor}

The current section describes some security concepts and how an \R process can
be sandboxed using a combination of \ULIMIT and \texttt{MAC} tools. The methods
are illustrated using the \RAppArmor package: an implementation based on
\Linux and \AppArmor. \AppArmor (``Application Armor'') is a
security module for the \Linux kernel. It allows for associating programs and
processes with \emph{security profiles} that restrict the capabilities and
permissions of that process. There are two ways of using \AppArmor. One is to
automatically associate a single, static security profile with every \R
process. This can only be done by the system administrator and does not require
\RAppArmor (see also section section \ref{usr.bin.r}). However, this approach is
somewhat limited in application and usually overly restrictive. We often need
something more flexible and dynamic, to set different policies, priorities and
restrictions for different users or tasks.

The \RAppArmor package on the other hand exposes \R functions that interface
directly to \Linux system calls related to setting privileges and restrictions
of a running process. Besides applying \AppArmor profiles, \RAppArmor also
interfaces to the \texttt{prlimit} call in \Linux, which sets \texttt{RLIMIT}
(resource limit) values on a process (\texttt{RLIMIT} are the \Linux
implementation of \ULIMIT). \Linux defines a number of \texttt{RLIMIT}'s,
which restrict things like memory use, number of processes, and stack size.
More on \texttt{RLIMIT} later in section \ref{RLIMITS}. Using \RAppArmor, the
sandboxing functionality is accessible directly from within the \R session, without the need for external tools or programs. Once \RAppArmor is installed,
any user can apply security profiles and restrictions to the running process; no
special permissions are needed. Furthermore, it allowed us to create the
\texttt{eval.secure} function: an abstraction which mimics \R's
\texttt{eval}, but has additional parameters to evaluate a call under a given
uid, priority, security policy and resource restrictions.

The \RAppArmor package brings the low level system security methods all the way
up to level of the \R language. Using \texttt{eval.secure}, different parts of
our code can run with different security restrictions with minimal overhead,
something we call \emph{dynamic sandboxing}. This is incredibly powerful in the
context of embedded services, and enables us to design applications which
explicitly allow for custom code execution; something that previously always had
to be avoided for security reasons. This new approach to scientific computing lies
at the core of the \texttt{OpenCPU} framework \citep{opencpu}, which exposes a
public HTTP API to run and share \R code on a central server.

\subsection[AppArmor profiles]{\AppArmor profiles}

The security policies are defined in profiles are the core of the \AppArmor
software. A profile is a set of rules in a text file using \AppArmor syntax. The
\Linux kernel translates these rules to a security policy that it will enforce
on the appropriate process. A brief introduction to the \AppArmor syntax is
given in section \ref{syntax}. The appendix of this paper contains some example
profiles that ship with the \RAppArmor package to get the user started.
When the package is installed through the Debian/Ubuntu installer (e.g.\ using
\texttt{apt-get}) the profiles are automatically copied to
\texttt{/etc/apparmor.d/rapparmor.d/}. Because profiles define file access
permissions based the location of files and directories on the file system,
they are to some extent specific to a certain \Linux distribution, as different
distributions have somewhat varying conventions on where files are located. The
example profiles included with \RAppArmor are based on the file layout of
the \pkg{r-base} package (and its dependencies) by \cite{batesusing} for
Debian/Ubuntu, currently maintained by Dirk Eddelbuettel.

The \texttt{RAppArmor} package and the included profiles work ``out of the
box'' on Ubuntu 12.04 (Precise) and up. Also it should be working on Debian
7.0 (Wheezy) and up, however as of writing of this paper, this distribution is
still in the ``testing'' phase. Furthermore the package has been successfully
build on OpenSuse 12.1. Note that Suse systems organize the file system in a
slightly different way than Ubuntu and Debian, so the profiles need to be
modified accordingly.

Again, we want to emphasize that the package and included profiles should mostly
be seen as a \emph{reference implementation}. Using the package we demonstrate
how to create a working sandbox in \R using \AppArmor. However, depending on
system and application, different policies might be appropriate. The \RAppArmor
package provides the tools to set security restrictions in \R and ships with
some example profiles to get the user started. However it is still up to the
administrator to determine which security policy is appropriate for a certain
system and context. The example profiles are a good starting point, but should
be fine-tuned for specific applications.

\subsection{Automatic installation}

The \RAppArmor package consists of an \R package and a number of security
profiles. On Ubuntu \Linux the package is most easily installed using the binary
packages provided through launchpad:

\begin{CodeChunk}
\begin{CodeInput}
sudo add-apt-repository ppa:opencpu/rapparmor
sudo apt-get update
sudo apt-get install r-cran-rapparmor
\end{CodeInput}
\end{CodeChunk}

One can also create the Ubuntu packages from the source \R package
using something along the lines of the following:

\begin{CodeChunk}
\begin{CodeInput}
wget http://cran.r-project.org/src/contrib/RAppArmor_0.5.0.tar.gz
tar xzvf RAppArmor_0.5.0.tar.gz
cd RAppArmor/
debuild -uc -us
cd ..
sudo dpkg -i r-cran-rapparmor_0.5.0-precise1_amd64.deb
\end{CodeInput}
\end{CodeChunk}

The \texttt{r-cran-rapparmor} Ubuntu package will automatically install required
dependencies and security profiles. The security profiles are installed in
\texttt{/etc/appamor.d/rapparmor.d/}.

\subsection{Manual installation}

To install the package on a distribution for which no installation package is
available, one might need a manual installation. To build the package manually
several steps are needed. First of all, one needs to make sure the required
dependencies are installed:

\begin{CodeChunk}
\begin{CodeInput}
sudo apt-get install r-base-dev libapparmor-dev apparmor
\end{CodeInput}
\end{CodeChunk}

Note that the package requires \R version 2.14 or higher. Also the
system needs to have an \AppArmor enabled \Linux kernel. After these packages
are installed, one can proceed installing \RAppArmor in \R, using
e.g:

\begin{CodeChunk}
\begin{CodeInput}
wget http://cran.r-project.org/src/contrib/RAppArmor_0.5.0.tar.gz
sudo R CMD INSTALL RAppArmor_0.5.0.tar.gz
\end{CodeInput}
\end{CodeChunk}

This will compile the \proglang{C} code and install the \R
package. After the package has been installed successfully, the security
profiles need to be copied to the \texttt{apparmor.d} directory:

\begin{CodeChunk}
\begin{CodeInput}
cd /usr/local/lib/R/site-library/RAppArmor/
sudo cp -Rf profiles/debian/* /etc/apparmor.d/
\end{CodeInput}
\end{CodeChunk}

Finally, the \AppArmor service needs to be restarted to load the new profiles.
Also we do not want to enforce default the \R profiles at this point yet:

\begin{CodeChunk}
\begin{CodeInput}
sudo service apparmor restart
sudo aa-disable usr.bin.r
\end{CodeInput}
\end{CodeChunk}

This should complete the installation. To verify if everything is working, start
\R and run the following code:

\begin{CodeChunk}
\begin{CodeInput}
library("RAppArmor")
aa_change_profile("r-base")
\end{CodeInput}
\end{CodeChunk}

If the code runs without any errors, the package has successfully been
installed.

\subsection[Linux security methods]{\Linux security methods}

The \RAppArmor package interfaces to a number of \Linux system calls that
are useful in the context of security and sandboxing. The advantage of calling
these directly from \R is that we can dynamically set the parameters
from within the \R process, as opposed to fixing them for every
\R session. Hence it is actually possible to execute some parts of an
application in a different security context other parts, which can be useful in
large applications.

The package defines a lot of low level functions that wrap around \Linux
\proglang{C} interfaces. However it is not required to study all of these
functions. For the end user, everything in the package comes together in the
powerful and convenient \texttt{eval.secure()} function. This function mimics
\texttt{eval()}, but it has additional parameters that define restrictions
which will be enforced to this specific evaluation. For example, one could use

\begin{CodeChunk}
\begin{CodeInput}
myresult <- eval.secure(myfun(), RLIMIT_AS = 10*1024*1024, profile="r-base")
\end{CodeInput}
\end{CodeChunk}

Which will call \texttt{myfun()} with a memory limit of 10MB and the ``r-base''
security profile (which is introduced in section \ref{r-base-intro}). The
\texttt{eval.secure} function works by creating a \emph{fork} of the current
process, and then sets hard limits, \texttt{uid} and \AppArmor profile on the
forked process, before evaluating the call. After the function returns, or when the
timeout is reached, the forked process is killed and cleaned up. This way, all
of the one-way security restrictions can be applied, and evaluations that
happen inside \texttt{eval.secure} won't have any side effects on the main
process.

\subsection{Setting user and group ID}

One of the most basic security methods is running a process as a specific user.
Especially within a system where the main process has superuser privileges
(which could be the case in for example a webserver), switching to a user with
limited privileges before evaluating any code is a wise thing to do. We could
even consider a design where every user of the application has a dedicated
user account on the \Linux machine. The \RAppArmor package implements the
functions \texttt{getuid, setuid, getgid, setgid}, which call out to the
respective \Linux system calls. Users and groups can either be specified
by their name, or as integer values as defined in the \texttt{/etc/passwd} file.

\begin{CodeChunk}
\begin{CodeInput}
R> library("RAppArmor")
R> system('whoami')
root
R> getuid()
[1] 0
R> getgid()
[1] 0
R> setgid(1000)
Setting gid...
R> setuid(1000)
Setting uid...
R> getgid()
[1] 1000
R> getuid()
[1] 1000
R> system('whoami')
jeroen
\end{CodeInput}
\end{CodeChunk}

The user/group ID can also be set inside the \texttt{eval.secure} function. In
this case it will not affect the main process; the UID is only set for the time
of the secure evaluation.

\begin{CodeChunk}
\begin{CodeInput}
R> eval(system('whoami', intern=TRUE))
[1] "root"
R> eval.secure(system('whoami', intern=TRUE), uid=1000)
[1] "jeroen"
R> eval(system('whoami', intern=TRUE))
[1] "root"
\end{CodeInput}
\end{CodeChunk}

Note that in order for \texttt{setgid} and \texttt{setuid} to work, the user
must have the appropriate capabilities in \Linux, which are usually
restricted to users with superuser privileges. The \texttt{getuid} and
\texttt{getgid} functions can be called by anyone.

\subsection{Setting Task Priority}
\label{priority}

The \RAppArmor package implements interfaces for setting the scheduling priority
of a process, also called its \texttt{nice} value or \emph{niceness}. \Linux
systems use a priority system with 40 priorities, ranging from -20 (highest
priority) to 19 (lowest priority). By default most processes run with nice
value 0. Users without superuser privileges can only increase this value, i.e.
lower the priority of the process. In \RAppArmor the \texttt{getpriority} and
\texttt{setpriority} functions change the priority of the current session:

\begin{CodeChunk}
\begin{CodeInput}
R> getpriority()
[1] 0
R> setpriority(10)
Setting priority...
[1] 10
R> setpriority(5)
Setting priority...
Error in setpriority(5) : Failed to set priority to: 5.
Error: 13
\end{CodeInput}
\end{CodeChunk}

Again, the \texttt{eval.secure} function is used to run a function or code block
with a certain priority without affecting the priority of the main \R session:

\begin{CodeChunk}
\begin{CodeInput}
R> eval.secure(system('nice', intern=T), priority=10)
Setting priority...
[1] "10"
R> getpriority()
[1] 0
\end{CodeInput}
\end{CodeChunk}


\subsection{Linux Resource Limits (RLIMIT)}
\label{RLIMITS}

Linux defines a number of \texttt{RLIMIT} values that can be used to set
resource limits on a process \citep{linuxrlimit}. The \RAppArmor package
has functions to get/set to the following RLIMITs:

\begin{itemize}
  \item \texttt{RLIMIT\_AS} -- The maximum size of the process's virtual memory
  (address space).
  \item \texttt{RLIMIT\_CORE} -- Maximum size of core file.
  \item \texttt{RLIMIT\_CPU} -- CPU time limit.
  \item \texttt{RLIMIT\_DATA} --  The maximum size of the process's data
  segment.
  \item \texttt{RLIMIT\_FSIZE} --  The maximum size of files that the process
  may create.
  \item \texttt{RLIMIT\_MEMLOCK} -- Number of memory that may be locked into
  RAM.
  \item \texttt{RLIMIT\_MSGQUEUE} -- Max number of bytes that can be allocated
  for POSIX message queues
  \item \texttt{RLIMIT\_NICE} --  Specifies a ceiling to which the process's
  nice value (priority).
  \item \texttt{RLIMIT\_NOFILE} -- Limit maximum file descriptor number that can
  be opened.
  \item \texttt{RLIMIT\_NPROC} -- Maximum number of processes (or, more
  precisely on Linux, threads) that can be created by the user of the calling process.
  \item \texttt{RLIMIT\_RTPRIO} -- Ceiling on the real-time priority that may be
  set for this process.
  \item \texttt{RLIMIT\_RTTIME} -- Limit on the amount of CPU time that a
  process scheduled under a real-time scheduling policy may consume without making a blocking system call.
  \item \texttt{RLIMIT\_SIGPENDING} -- Limit on the number of signals that may
  be queued by the user of the calling process.
  \item \texttt{RLIMIT\_STACK} -- The maximum size of the process stack.
\end{itemize}

For all of the above \texttt{RLIMITs}, the \RAppArmor package implements a
function which name is equivalent to the non-capitalized name of the
\texttt{RLIMIT}. For example to get/set \texttt{RLIMIT\_AS}, one can call
\texttt{rlimit\_as()}. Every \texttt{rlimit\_} function has exactly 3 parameters:
\texttt{hardlim}, \texttt{softlim}, and \texttt{pid}. Each argument is
specified as an integer value. The \texttt{pid} arguments points to the target
process. When this argument is omitted, the calling process is targeted. When
the \texttt{softlim} is omitted, it is set equal to the \texttt{hardlim}.

The soft limit is the value that the kernel enforces for the corresponding
resource. The hard limit acts as a ceiling for the soft limit: an unprivileged
process may only set its soft limit to a value in the range from 0 up to the
hard limit, and (irreversibly) lower its hard limit. A  privileged process
(under  \Linux:  one  with  the \texttt{CAP\_SYS\_RESOURCE} capability) may make
arbitrary changes to either limit value. When the function is called without any
arguments, it prints the current limits to \texttt{STDOUT}. \citep{linuxrlimit}

\begin{CodeChunk}
\begin{CodeInput}
R> library("RAppArmor")
R> rlimit_as()
RLIMIT_AS:
Current limits: soft=-1; hard=-1
R> A <- rnorm(1e7)
R> rm(A)
R> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 185467  5.0     407500 10.9   350000  9.4
Vcells 176590  1.4    8743611 66.8 10182143 77.7
>
R> rlimit_as(10*1024*1024)
RLIMIT_AS:
Previous limits: soft=-1; hard=-1
Current limits: soft=10485760; hard=10485760
R> A <- rnorm(1e7)
Error: cannot allocate vector of size 76.3 Mb
\end{CodeInput}
\end{CodeChunk}

Note that a process owned by a user without superuser privileges can only modify
\texttt{RLIMIT} to more restrictive values. However, using \texttt{eval.secure},
a more restrictive \texttt{RLIMIT} can be applied to a single evaluation without
any side effects on the main process:

\begin{CodeChunk}
\begin{CodeInput}
R> library("RAppArmor")
R> A <- eval.secure(rnorm(1e7), RLIMIT_AS = 10*1024*1024);
Error: cannot allocate vector of size 76.3 Mb
R> A <- rnorm(1e7)
\end{CodeInput}
\end{CodeChunk}

The exact meaning of the different limits can be found in the \texttt{RAppArmor}
package documentation (e.g.\ \texttt{?rlimit\_as}) or in the documentation of
the distribution \citep{ubunturlimit}.

\subsection[Activating AppArmor profiles]{Activating \AppArmor profiles}

The \RAppArmor package implements three calls to the \Linux kernel related
to applying \AppArmor profiles: \texttt{aa\_change\_profile},
\texttt{aa\_change\_hat} and \texttt{aa\_revert\_hat}. Both the
\texttt{aa\_change\_profile} and \texttt{aa\_change\_hat} functions take a
parameter named \texttt{profile}: a character string identifying the name of
the profile. This profile has to be preloaded by the kernel, before it can be
applied to a process. The easiest way to load profiles is to copy them to the
directory \texttt{/etc/apparmor.d} and then run \texttt{sudo service apparmor
restart}.

The main difference between a \emph{profile} and a \emph{hat} is that switching
profiles is an irreversible action. Once the profile has been associated with
the current process, the process cannot call \texttt{aa\_change\_profile} again
to escape from the profile (that would defeat the purpose). The only exception
to this rule are profiles that contain an explicit \texttt{change\_profile}
directive. The \texttt{aa\_change\_hat} function on the other hand is designed to
associate a process with a security profile in a way that does allows escaping
out of the security profile. In order to realize this, the
\texttt{aa\_change\_hat} takes a second argument called \texttt{magic\_token},
which defines a secret key that can be used to \emph{revert} the hat. When
\texttt{aa\_revert\_hat} is called with the same \texttt{magic\_token} that
was used in \texttt{aa\_change\_hat}, the security restrictions are
relieved.

Using \texttt{aa\_change\_hat} to switch in and out of profiles is an easy way
to get started with \RAppArmor and test some security policies. However it
should be emphasized that using \emph{hats} instead of \emph{profiles} is also a
security risk and should be avoided in production settings. It is important to
realize that if the code running in the sandbox can find a way of discovering
the value of the \texttt{magic\_token} (e.g.\ from memory, command history or log
files), it will be able to escape from the sandbox. Hence
\texttt{aa\_change\_hat} should only be used to prevent general purpose
malicious activity, e.g.\ when testing a new \R package. When hosting services
or otherwise exposing an environment that might be specifically targeted,
hackers could write code that attempts to find the magic token and revert the
hat. Therefore it is recommended to only use \texttt{aa\_change\_profile} or
\texttt{eval.secure} in production settings. When a profile is applied to a
process using \texttt{aa\_change\_profile} or \texttt{eval.secure}, the kernel
will keep enforcing the security policy on the respective process and all of its
children until they die, no matter what.

The \RAppArmor package ships with a profile called \emph{testprofile} which
contains a hat called \emph{testhat}. We use this profile to demonstrate the
functionality. The profiles have been defined such that \emph{testprofile}
allows access to \texttt{/etc/group} but denies access to \texttt{/etc/passwd}.
The \emph{testhat} denies access to both \texttt{/etc/passwd} and
\texttt{/etc/group}.

\begin{CodeChunk}
\begin{CodeInput}
R> library("RAppArmor");
R> result <- read.table("/etc/passwd")

R> aa_change_profile("testprofile")
Switching profiles...
R> passwd <- read.table("/etc/passwd")
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") : cannot open file '/etc/passwd': Permission denied
R> group <- read.table("/etc/group")

R> mytoken <- 13337;
R> aa_change_hat("testhat", mytoken);
Setting Apparmor Hat...

R> passwd <- read.table("/etc/passwd")
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") : cannot open file '/etc/passwd': Permission denied
R> group <- read.table("/etc/group")
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") : cannot open file '/etc/group': Permission denied

R> aa_revert_hat(mytoken);
Reverting AppArmor Hat...

R> passwd <- read.table("/etc/passwd")
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") : cannot open file '/etc/passwd': Permission denied
R> group <- read.table("/etc/group")
\end{CodeInput}
\end{CodeChunk}

Just like for \texttt{setuid} and \texttt{rlimit} functions,
\texttt{eval.secure} can be used to enforce an \AppArmor security profile on a
single call, witout any side effects. The \texttt{eval.secure} function uses
\texttt{aa\_change\_profile} and is therefore most secure.

\begin{CodeChunk}
\begin{CodeInput}
R> out <- eval(read.table("/etc/passwd"))
R> nrow(out)
[1] 68
R> out <- eval.secure(read.table("/etc/passwd"), profile="testprofile")
Error in file(file, "rt") : cannot open the connection
\end{CodeInput}
\end{CodeChunk}

\subsection[AppArmor without RAppArmor]{\AppArmor without \RAppArmor}
\label{usr.bin.r}

The \RAppArmor package allows us to dynamically load an \AppArmor profile
from within an \R session. This gives a great deal of flexibility. However, it
is also possible to use \AppArmor without the \RAppArmor package, by setting a
single profile to be loaded with any running \R process.

To do so, the RAppArmor package ships with a profile named \texttt{usr.bin.r}.
At the installation of the package, this file is copied to \texttt{/etc/apparmor.d/}.
This file is basically a copy of the \texttt{r-user} profile in appendix
\ref{r-user}, however with a small change: where \texttt{r-user} defines
a named profile with
\begin{verbatim}
  profile r-user {
    ...
  }
\end{verbatim}
the \texttt{usr.bin.r} file defines a profile specific to a filepath:
\begin{verbatim}
  /usr/bin/R {
    ...
   }
\end{verbatim}

When using the latter syntax, the profile is automatically associated every time
the file \texttt{/usr/bin/R} is executed (which is the file that runs when
\R is entered in the shell). This way we can set some default security
restrictions for our daily work. Profiles tied to a specific program can be
activated by the administrator using:
\begin{verbatim}
  sudo aa-enforce usr.bin.r
\end{verbatim}
This will enforce the security restrictions on every new \R process that is
started. To disable the profile, the administrator can run:
\begin{verbatim}
  sudo aa-disable usr.bin.r
\end{verbatim}
After stop enforcing the profile, the \R program can be started without any
restrictions.

Note that the \texttt{usr.bin.r} profile does \textbf{not} grant permission to
change profiles. Hence, once the \texttt{usr.bin.r} profile is in enforce mode,
we cannot use the \texttt{eval.secure} or \texttt{aa\_change\_profile} functions
from the \RAppArmor package to change into a different profile, as this
would be a security hole.

\subsection{Learning using complain mode}

Finally \AppArmor allows the administrator to set profiles in \emph{complain
mode}, which is also called \emph{learning mode}.
\begin{verbatim}
  sudo aa-complain usr.bin.r
\end{verbatim}
This is useful for developing new profiles. When a profile is set in complain
mode, security restrictions are not actually enforced; instead all violations
of the security policy are logged to the \texttt{syslog} and \texttt{kern.log}
files. This is a powerful way of creating new profiles: one can set a program in
complain mode during regular use, and afterwards the log files can be used to
study violations of the current policy. From these violations we can determine
which permissions will have to be added to the profile to make the program work
under normal behavior. \AppArmor even ships with a powerful utility named
\texttt{aa-logprof} which helps the administrator by parsing log files and
suggesting new rules to be added to the profile. This is a nice way of
debugging a profile, and figuring out which permissions exactly a program
requires to do its work.

\section[Profiling R: Defining security policies]{Profiling \R: Defining security policies}

The ``hard'' part of the problem is actually profiling \R. With
profiling we mean defining the policies: which files and directories should
\R be allowed to read and write to? Which external programs is it
allowed to execute? Which libraries or shared modules it allowed to load, etc.
We want to minimize ways in which the process could potentially damage the
system, but we don't want to be overly restrictive either: preferebly, users
should be able to do anything they normally do in \R. Because \R is
such a complete system with a big codebase and a wide range of functionality,
the base system actually already requires quite a lot of access to the file
system.

As often, there is no ``one size fits all'' solution. Depending on which
functionality is needed for an application we might want to grant or deny
certain privileges. We might even want to execute some parts of a process with
tighter privileges than other parts. For example, within a web service, the
service process should be able to write to system log files, which should not be
writable by custom code from a user. We might also want to be more strict on
some users than others, e.g.\ allow all users to run code, but only allow
privileged users to install a new package.

\subsection[AppArmor policy configuration syntax]{\AppArmor policy configuration
syntax}
\label{syntax}

The \emph{AppArmor policy configuration syntax} is used to define the access
control profiles in \AppArmor. Other mandatory access control systems
might implement different functionality and require other syntax, but in the end
they address mostly similar issues. \AppArmor is quite advanced and provides
access control over many of the features and resources found in the \Linux
kernel, e.g.\ file access, network rules, \Linux capability modes, mounting
rules, etc. All of these can be useful, but most of them are very application
specific. Furthermore, the policy syntax has some meta functionality that
allows for defining \emph{subprofiles}, and \emph{includes}.

The most important form of access control which will be the focus of the
remaining of the section are \emph{file permission access modes}. Once \AppArmor
is enforcing mandatory access control, a process can only access files and
directories on the system for which it has explicitly been granted access in
its security profile. Because in \Linux almost everything is a file
(even sockets, devices, etc) this gives a great deal of control. \AppArmor
defines a number of access modes on files and directories, of which the most
important ones are:

\begin{itemize}
  \item[] \texttt{r} -- read file or directory.
  \item[] \texttt{w} -- write to file or directory.
  \item[] \texttt{m} -- load file in memory.
  \item[] \texttt{px} -- discrete profile execute of executable file.
  \item[] \texttt{cs} -- transition to subprofile for executing a file.
  \item[] \texttt{ix} -- inherit current profile for executing a file.
  \item[] \texttt{ux} -- unconfined execution of executable file (dangerous).
\end{itemize}

Using this syntax we will present some example profiles for \R. Because the
profiles are defined using absolute paths of system files, we will assume the
standard file layout for Debian and Ubuntu systems. This includes files that
are part of \texttt{r-base} and other packages that are used by \R, e.g.
\texttt{texlive}, \texttt{libxml2}, \texttt{bash}, \texttt{libpango},
\texttt{libcairo}, etc.

\subsection[Profile: r-base]{Profile: \texttt{r-base}}
\label{r-base-intro}

Appendix \ref{r-base} contains a profile that we have named \texttt{r-base}.
It is a fairly basic and general profile. It grants read/load access to all
files in common shared system directories, e.g.\ \texttt{/usr/lib,
/usr/local/lib, /usr/share}, etc. However, the default profile only grants
write access inside \texttt{/tmp}, not in e.g.\ the home directory. Furthermore,
\R is allowed to execute any of the shell commands in \texttt{/bin}
or \texttt{/usr/bin} for which the program will inherit the restrictions.

\begin{CodeChunk}
\begin{CodeInput}
R> library("RAppArmor")
R> aa_change_profile("r-base")
Switching profiles...

R> list.files("/")
character(0)
R> list.files("~")
character(0)
R> file.create("~/test")
[1] FALSE
R> list.files("/tmp")
character(0)
R> install.packages("wordcloud")
Error opening file for reading: Permission denied

R> library("ggplot2");
R> setwd(tempdir())
R> pdf("test.pdf")
R> qplot(speed, dist, data=cars);
R> dev.off()
null device
          1
R> list.files()
[1] "downloaded_packages"
[2] "libloc_107_669a3e12.rds"
[3] "libloc_118_46fd5f8e.rds"
[4] "libloc_128_97f33314.rds"
[5] "pdf6d1117f7d683"
[6] "repos_http%3a%2f%2fcran.stat.ucla.edu%2fsrc%2fcontrib.rds"
[7] "test.pdf"
R> file.remove("test.pdf")
[1] TRUE
\end{CodeInput}
\end{CodeChunk}

The \texttt{r-base} profile effectively protects \R from most malicious
activity, while still allowing access to all of the libraries, fonts, icons, and
programs that it might need. One thing to note is that the profile
does not allow listing of the contents of \texttt{/tmp}, but it does allow full
\texttt{rw} access on any of its subdirectories. This is to prevent one process
from reading/writing files in the temp directory of another active \R process
(given that it cannot discover the name of the other temp directory).

The \texttt{r-base} profile is a quite liberal and general purpose profile. When
using \AppArmor in a more specific application, it is recommended to make the
profile a bit more restrictive by specifying exactly \emph{which} of the
packages, shell commands and system libraries should be accessible by the
application. That could prevent potential problems when vulnerabilities are
discovered in some of the standard libraries.

\subsection[Profile: r-compile]{Profile: \texttt{r-compile}}

The \texttt{r-base} profile does not allow access to the compiler, nor does it
allow for loading (\texttt{m}) or execution (\texttt{ix}) of files in places
where it can also write. If we want user to be able to compile e.g.
\Cpp code, we will need to give it access to the compiler. In order
to do so, we need to add these lines:

\begin{verbatim}
/usr/include/** r,
/usr/lib/gcc/** rix,
/tmp/** rmw,
\end{verbatim}

Note especially the last line. The \texttt{m} allows \R to load shared
objects into memory from anywhere under \texttt{/tmp}. This is needed to load
the compiled code after it has been installed to a temporary directory. Note
that this does not come without a cost: compiled code can potentially contain
malicious code or even exploits that can do harm when loaded into memory. If
this privilege is not needed, it is generally recommended to only allow
\texttt{m} and {ix} access modes on files that have been installed by the
system administrator. The new profile including these rules ships with the
package as \texttt{r-compile} and is also printed in appendix \ref{r-compile}.

After adding the lines above and reloading the profile, it should be possible to
compile a package that contains \Cpp code and install it to somewhere
in \texttt{/tmp}:

\begin{CodeChunk}
\begin{CodeInput}
R> eval.secure(install.packages("wordcloud", lib=tempdir()), profile="r-compile");
trying URL 'http://cran.stat.ucla.edu/src/contrib/wordcloud_2.0.tar.gz'
downloaded 36 Kb

* installing *source* package 'wordcloud' ...
** package 'wordcloud' successfully unpacked and MD5 sums checked
** libs
g++ -I/usr/share/R/include -DNDEBUG -I"/usr/local/lib/R/site-library/Rcpp/include"
   -fpic  -O3 -pipe  -g  -c layout.cpp -o layout.o
g++ -shared -o wordcloud.so layout.o -L/usr/local/lib/R/site-library/Rcpp/lib
   -lRcpp -Wl,-rpath,/usr/local/lib/R/site-library/Rcpp/lib -L/usr/lib/R/lib -lR
installing to /tmp/RtmpFCM6WS/wordcloud/libs
** R
** data
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded

* DONE (wordcloud)

The downloaded source packages are in
	'/tmp/RtmpFCM6WS/downloaded_packages'
\end{CodeInput}
\end{CodeChunk}

\subsection[Profile: r-user]{Profile: \texttt{r-user}}

Appendix \ref{r-user} defines a profile named \texttt{r-user}. This profile is
designed to be a nice balance between security and freedom for day to day use of
R. It extends the \texttt{r-compile} profile with some additional privileges
with respect to the user's home directory. The variable \texttt{@\{HOME\}} is
defined in the \texttt{tunables/global} include and matches the location of the
user's home directory, i.e.\ \texttt{/home/jeroen} for a user named ``jeroen''.
The profile assumes that there is a directory named \R directly inside
the home directory (e.g \texttt{/home/jeroen/R}), to which \R can read and
write. Furthermore, \R can load and execute files in the directories
\texttt{i686-pc-linux-gnu-library} and \texttt{x86\_64-pc-linux-gnu-library}
inside of this \R directory. These are the standard locations where
\R installs a user's personal package library.

Using the \texttt{r-user} profile, the user will be able to do most of his day
to day work, including installing and loading new packages in his personal
library, while still being protected against most malicious activities. The
\texttt{r-user} profile is also the basis of the default \texttt{usr.bin.r}
profile mentioned in section \ref{usr.bin.r}.

\subsection{Installing packages}

An additional privilege that might be needed in some situations is the option to
install packages to the system's global library, which is readable by all
users. In order to allow this, a profile needs to include write access to the
\texttt{site-library} directory:

\begin{verbatim}
 /usr/local/lib/R/site-library/ rw,
 /usr/local/lib/R/site-library/** rwm,
\end{verbatim}

After adding this line to a profile, the policy will allow for installing R
packages to the global site library. However, note that \AppArmor does not
replace, but \emph{supplements} the standard access control system. Hence if a
user does not have permission to write into this directory (either by
standard Unix access controls or by running with superuser privileges), it will
still not be able to install packages in the global site library, even though
the \AppArmor profile does grant this permission.

\section{Concluding remarks}

In this paper the reader was introduced to some potential security issues
related to the use of the \R software. We hope to have raised
awareness that security is an increasingly important concern for the
\R user, but also that addressing this issue could open doors to new
applications of the software. The \RAppArmor package was introduced as an
example that demonstrates how some security issues could be addressed using
facilities from the operating system, in this case \Linux. This
implementation provides a starting point for creating a sandbox in \R,
but as was emphasized throughout the paper, it is still up to the administrator
to actually design security policies that are appropriate for a certain
application or system.

Our package uses the \AppArmor software from the \Linux kernel,
which works for us, but this is just one way to approach the issue.
\Linux has two other mandatory access control systems that are worth
exploring: \texttt{TOMOYO} and \texttt{SELinux}. Especially the latter is known
to be very sophisticated, but also extremely hard to set up. Other more recent
technology that might be interesting is provided by \texttt{Linux CGroups}.
Using \texttt{CGroups}, control of allocation and security is managed by
hierarchical process groups. The upcoming \texttt{LXC} (Linux Containers) build
on \texttt{CGroups} to provide virtual environments which have their own
process and network space. A completely different direction is suggested by
\texttt{renjin} \citep{renjin}, a \texttt{JVM}-based Interpreter for the R
Language. If \R code can be executed though the \texttt{JVM}, we might be able
to use some tools from the \Java community to address similar issues.
Finally we curious to see what the \texttt{BSD} community has to offer in this
area, as \texttt{BSD} distributions are known to have a lot of emphasis on
security in the design of the operating system.

However, no matter which tools are used, security always comes down to the trade
off between \emph{use} and \emph{abuse}. This has a major human aspect to it,
and is a learning process in itself. A balance has to be found between providing
enough freedom to use facilities as desired, yet minimize opportunities for
undesired activity. Apart from the technical parameters, a good balance also
depends on factors like what exactly is considered undesired and how well you
know your users. For example a job using 20 parallel cores might be considered
as abusive by many administrators, but might actually be regular use for a MCMC
simulation study on a supercomputer. Security policies are not unlike legal
policies in the sense that they won't always work out as intended, and have to
evolve over time as part of an iterative process. It might not be until an
application is put in production that users start complaining about their
favorite package not working, or that it turns out that the system is being
abused in a way that was hard to foresee. We hope that our research will
contribute to this process and help take a step in the direction of a safer \R.

\section{Acknowledgments}

We owe a thank you to several people who have been specifically helpful in the
course of this research. Things would not have been possible without their 
valuable criticism, support and feedback. Among others these include Dirk
Eddelbuettel and Michael Rutter for providing excellent packages for the Debian
and Ubuntu distributions on which we largely build our implementation. Daróczi
Gergely and Aleksandar Blagotić for always being ``early adopters'' (guinea
pigs) and putting things to the test. And finally John Johansen, Seth Arnold and
Steve Beattie have been very helpful (and patient) by providing support and
feedback through the \texttt{apparmor} mailing lists.




\begin{appendices}
\section{Example profiles}

This appendix prints some of the example profiles that ship with the
\RAppArmor package. To load them in \AppArmor, simply copy-paste the
profile into a file that you put in the directory \texttt{/etc/apparmor.d} and
then run \texttt{sudo service apparmor restart}. You should then be able to load
them into an \R session using either the \texttt{aa\_change\_profile}
or \texttt{secure.eval} function from the \texttt{RAppArmor} package.

\subsection[Profile: r-base]{Profile: \texttt{r-base}}
\label{r-base}

\begin{verbatim}
#include <tunables/global>
profile r-base {
        #include <abstractions/base>
        #include <abstractions/nameservice>

        /bin/* rix,
        /etc/R/ r,
        /etc/R/* r,
        /etc/fonts/** mr,
        /etc/xml/* r,
        /tmp/** rw,
        /usr/bin/* rix,
        /usr/lib/R/bin/* rix,
        /usr/lib{,32,64}/** mr,
        /usr/lib{,32,64}/R/bin/exec/R rix,
        /usr/local/lib/R/** mr,
        /usr/local/share/** mr,
        /usr/share/** mr,
}
\end{verbatim}


\subsection[Profile: r-compile]{Profile: \texttt{r-compile}}
\label{r-compile}

\begin{verbatim}
#include <tunables/global>
profile r-compile {
        #include <abstractions/base>
        #include <abstractions/nameservice>

        /bin/* rix,
        /etc/R/ r,
        /etc/R/* r,
        /etc/fonts/** mr,
        /etc/xml/* r,
        /tmp/** rmw,
        /usr/bin/* rix,
        /usr/include/** r,
        /usr/lib/gcc/** rix,		
        /usr/lib/R/bin/* rix,
        /usr/lib{,32,64}/** mr,
        /usr/lib{,32,64}/R/bin/exec/R rix,
        /usr/local/lib/R/** mr,
        /usr/local/share/** mr,
        /usr/share/** mr,
}
\end{verbatim}

\subsection[Profile: r-user]{Profile: \texttt{r-user}}
\label{r-user}

\begin{verbatim}
#include <tunables/global>
profile r-user {
        #include <abstractions/base>
        #include <abstractions/nameservice>
	
        capability kill,
        capability net_bind_service,
        capability sys_tty_config,
	
        @{HOME}/ r,
        @{HOME}/R/ r,
        @{HOME}/R/** rw,
        @{HOME}/R/{i686,x86_64}-pc-linux-gnu-library/** mrwix,
        /bin/* rix,
        /etc/R/ r,
        /etc/R/* r,
        /etc/fonts/** mr,
        /etc/xml/* r,
        /tmp/** mrwix,
        /usr/bin/* rix,
        /usr/include/** r,
        /usr/lib/gcc/** rix,		
        /usr/lib/R/bin/* rix,
        /usr/lib{,32,64}/** mr,
        /usr/lib{,32,64}/R/bin/exec/R rix,
        /usr/local/lib/R/** mr,
        /usr/local/share/** mr,
        /usr/share/** mr,
}
\end{verbatim}



\section{Security unit tests}

This appendix prints a number of unit tests that contain malicious code and
which should be prevented by any sandboxing tool.

\subsection{Access system files}

Usually \R has no business in the system logs, and these are not included in the
profiles. The codechunk below attempts to read the syslog file.
\begin{CodeChunk}
\begin{CodeInput}
readSyslog <- function(){
	readLines('/var/log/syslog');
}
\end{CodeInput}
\end{CodeChunk}
When executing this with a r-user profile, access to this file is denied,
resulting in an error:
\begin{CodeChunk}
\begin{CodeInput}
R> eval.secure(readSyslog(), profile='r-user')
Switching profiles...
Error in file(con, "r") : cannot open the connection
\end{CodeInput}
\end{CodeChunk}

\subsection{Access user files}
\label{creditcard}

Access to system files can to some extend by prevented by running processes as
non privileged users. But it is easy to forget that also the user's personal
files can contain senstive information. Below a simple function that scans the
\texttt{Documents} directory of the current user for files that contain credit
card numbers.

\begin{CodeChunk}
\begin{CodeInput}
findCreditCards <- function(){
  pattern <- "([0-9]{4}[- ]){3}[0-9]{4}"
  for (filename in list.files("~/Documents", full.names=TRUE, recursive=TRUE)){
    if(file.info(filename)$size > 1e6) next;
    doc <- readLines(filename)
    results <- gregexpr(pattern, doc)
    output <- unlist(regmatches(doc, results));
    if(length(output) > 0){
      cat(paste(filename, ":", output, collapse="\n"), "\n")
    }
  }
}
\end{CodeInput}
\end{CodeChunk}

This example prints the credit card numbers to the user, but it would be quite
easy to post them to some server on the internet. For this reason the
\texttt{r-user} profile denies access to the user's home dir, except for the
\texttt{{\raise.17ex\hbox{$\scriptstyle\sim$}}/R} directory.


\subsection{Limiting memory}

When a system or service is used by many users at the same time, it is important
that we cap the memory that can be used by a single process. The following
function generates a quite large matrix:

\begin{CodeChunk}
\begin{CodeInput}
memtest <- function(){
	A <- matrix(rnorm(1e7), 1e4);
}
\end{CodeInput}
\end{CodeChunk}

When \R tries to allocate more memory than allowed, it will throw an error:

\begin{CodeChunk}
\begin{CodeInput}
R> A <- eval.secure(memtest(), RLIMIT_AS = 1000*1024*1024)
RLIMIT_AS:
Previous limits: soft=-1; hard=-1
Current limits: soft=1048576000; hard=1048576000
R> rm(A)
R> gc()
         used (Mb) gc trigger  (Mb) max used  (Mb)
Ncells 193074 10.4     407500  21.8   350000  18.7
Vcells 299822  2.3   17248096 131.6 20301001 154.9


R> A <- eval.secure(memtest(), RLIMIT_AS = 100*1024*1024)
RLIMIT_AS:
Previous limits: soft=-1; hard=-1
Current limits: soft=104857600; hard=104857600
Error: cannot allocate vector of size 76.3 Mb
\end{CodeInput}
\end{CodeChunk}


\subsection{Limiting CPU time}
\label{cputime}

Suppose we are hosting a web service and we want to kill jobs that do not finish
in 5 seconds. Below is a snippet that will take much more than 5 seconds on most
machines. Note that because \R calling out to \texttt{C} code, it will not be
possible to terminate this function prematurely using R's \texttt{setTimeLimit}
or even using \texttt{CTRL+C} in an interactive console. If this would happen
inside of a bigger system, the entire service might become unresponsive.

\begin{CodeChunk}
\begin{CodeInput}
cputest <- function(){
  A <- matrix(rnorm(1e7), 1e3);
  B <- svd(A);
}
\end{CodeInput}
\end{CodeChunk}
In RAppArmor we have actually two different options to deal with this. The first
one is setting the \texttt{RLIMIT\_CPU} value. This will cause the kernel to
kill the process after 5 seconds:
\begin{CodeChunk}
\begin{CodeInput}
R> Sys.time()
[1] "2012-08-02 11:26:21 CEST"
R> x <- eval.secure(cputest(), RLIMIT_CPU=5)
RLIMIT_CPU:
Previous limits: soft=-1; hard=-1
Current limits: soft=5; hard=5
R> Sys.time()
[1] "2012-08-02 11:26:26 CEST"
R> print(x)
NULL
\end{CodeInput}
\end{CodeChunk}
However, this is actually a bit of a harsh measure: because the kernel actually
terminates the process after 5 seconds we have no control over what should
happen, nor can we throw an informative error. Setting \texttt{RLIMIT\_CPU} is
a bit like starting a job with a self-destruction timer. A more elegant
solution is to terminate the process from \R using the \texttt{timeout}
argument from the \texttt{eval.secure} function. Because the actual job is processed in a fork, the parent process stays responsive, and is used to kill the child process.
\begin{CodeChunk}
\begin{CodeInput}
R> Sys.time()
[1] "2012-07-08 16:59:06 CEST"
R> eval.secure(cputest(), timeout=5)
Error: R call did not return within 5 seconds. Terminating process.
R> Sys.time()
[1] "2012-07-08 16:59:11 CEST"
\end{CodeInput}
\end{CodeChunk}

One could even consider a Double Dutch solution by setting both \texttt{timeout}
and a slightly higher value for \texttt{RLIMIT\_CPU}, so that if all else fails,
the kernel will end up killing the process and its children.

\subsection{Fork bomb}

A fork bomb is a process that spawns many child processes, which often results
in the operating system getting stuck to a point where it has to be rebooted.
Performing a fork bomb in \R is quite easy and requires no special privileges:
\begin{CodeChunk}
\begin{CodeInput}
forkbomb <- function(){
  repeat{
    parallel::mcparallel(forkbomb());
  }
}
\end{CodeInput}
\end{CodeChunk}
Do not call this function outside sandbox, because it will make the machine
unresponsive. However, inside our sandbox we can use the \texttt{RLIMIT\_NPROC}
to limit the number of processes the user is allowed to own:
\begin{CodeChunk}
\begin{CodeInput}
R> eval.secure(forkbomb(), RLIMIT_NPROC = 20)
RLIMIT_NPROC:
Previous limits: soft=39048; hard=39048
Current limits: soft=20; hard=20
Error in mcfork() :
  unable to fork, possible reason: Resource temporarily unavailable
\end{CodeInput}
\end{CodeChunk}
Note that the process count is based on the \Linux user. Hence if the same
\Linux user already has a number of other processes, which is usually the case for
non-system users, the cap has to be higher than this number. Also note
that in some \Linux configurations, the root user is exempted from the
\texttt{RLIMIT\_NPROC} limit.

Different processes owned by a single user can enforce different \texttt{NPROC}
limits, however in the actual process count all active processes from the
current user are taken into account. Therefore it might make sense to create a
separate Linux system user that is only used to process \R jobs. That way
\texttt{RLIMIT\_NPROC} actually corresponds to the number of concurrent \R
processes. The \texttt{eval.secure} arguments \texttt{uid} and \texttt{gid}
can be used to switch Linux users before evaluating the call. E.g to add a
system user in \Linux, run:
\begin{CodeChunk}
\begin{CodeInput}
sudo useradd testuser --system -U -d/tmp -c"RAppArmor Test User"
\end{CodeInput}
\end{CodeChunk}
If the main \R process has superuser privileges, incoming call can be
evaluated as follows:
\begin{CodeChunk}
\begin{CodeInput}
eval.secure(run_job(), uid="testuser", RLIMIT_NPROC=10, timeout=60)
\end{CodeInput}
\end{CodeChunk}


\end{appendices}



%\bibliographystyle{apalike-url}	% (uses file "plain.bst")
\bibliography{document}

\end{document}
